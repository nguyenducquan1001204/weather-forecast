"""
Script crawl v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu d·ª± b√°o th·ªùi ti·∫øt t·ª´ thoitiet360.edu.vn
ƒê·ªÉ so s√°nh v·ªõi d·ª± ƒëo√°n c·ªßa h·ªá th·ªëng
"""
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import time
import subprocess
import os
from datetime import datetime, timedelta
import sys

if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# L·∫•y th∆∞ m·ª•c n∆°i script n√†y ƒë∆∞·ª£c ƒë·∫∑t
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

def check_and_pull_from_github():
    """Ki·ªÉm tra v√† pull c·∫≠p nh·∫≠t t·ª´ GitHub n·∫øu c√≥"""
    print("="*70)
    print("KIEM TRA CAP NHAT TU GITHUB")
    print("="*70)
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ƒêang ki·ªÉm tra c·∫≠p nh·∫≠t...")
    print(f"  Th∆∞ m·ª•c l√†m vi·ªác: {SCRIPT_DIR}")
    
    try:
        # Chuy·ªÉn ƒë·∫øn th∆∞ m·ª•c script ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng v·ªã tr√≠
        os.chdir(SCRIPT_DIR)
        
        # L·∫•y c√°c thay ƒë·ªïi m·ªõi nh·∫•t
        result = subprocess.run(
            ['git', 'fetch', 'origin', 'main'],
            capture_output=True,
            text=True,
            cwd=SCRIPT_DIR
        )
        
        if result.returncode != 0:
            print(f"  ‚ö†Ô∏è  Kh√¥ng th·ªÉ fetch t·ª´ GitHub (c√≥ th·ªÉ kh√¥ng ph·∫£i git repo): {result.stderr[:100]}")
            return False
        
        # Ki·ªÉm tra xem c√≥ commit m·ªõi kh√¥ng
        result = subprocess.run(
            ['git', 'rev-list', '--count', 'HEAD..origin/main'],
            capture_output=True,
            text=True,
            cwd=SCRIPT_DIR
        )
        
        if result.returncode != 0:
            print(f"  ‚ö†Ô∏è  Kh√¥ng th·ªÉ ki·ªÉm tra commits: {result.stderr[:100]}")
            return False
        
        commits_behind = int(result.stdout.strip()) if result.stdout.strip() else 0
        
        if commits_behind > 0:
            print(f"  üì• T√¨m th·∫•y {commits_behind} commit(s) m·ªõi. ƒêang pull c·∫≠p nh·∫≠t...")
            
            # Pull c√°c thay ƒë·ªïi
            result = subprocess.run(
                ['git', 'pull', 'origin', 'main'],
                capture_output=True,
                text=True,
                cwd=SCRIPT_DIR
            )
            
            if result.returncode == 0:
                print(f"  ‚úÖ ƒê√£ pull th√†nh c√¥ng {commits_behind} commit(s)")
                print(f"  üìÑ C√°c file ƒë√£ c·∫≠p nh·∫≠t: thoitiet360_data.csv, database, v√† c√°c file kh√°c")
                return True
            else:
                print(f"  ‚ö†Ô∏è  L·ªói khi pull: {result.stderr[:100]}")
                return False
        else:
            print("  ‚úÖ ƒê√£ c·∫≠p nh·∫≠t m·ªõi nh·∫•t, kh√¥ng c√≥ thay ƒë·ªïi")
            return False
            
    except Exception as e:
        print(f"  ‚ö†Ô∏è  L·ªói khi ki·ªÉm tra GitHub: {str(e)[:100]}")
        return False

# Mapping th√†nh ph·ªë
CITY_MAPPING = {
    'ha-noi': 'H√† N·ªôi',
    'vinh': 'Vinh',
    'ho-chi-minh': 'H·ªì Ch√≠ Minh'
}

# URL mapping
CITY_URLS = {
    'ha-noi': 'https://thoitiet360.edu.vn/ha-noi/3-ngay-toi',
    'vinh': 'https://thoitiet360.edu.vn/nghe-an/vinh/3-ngay-toi',
    'ho-chi-minh': 'https://thoitiet360.edu.vn/ho-chi-minh/3-ngay-toi'
}

def parse_temperature(temp_str):
    """Parse nhi·ªát ƒë·ªô t·ª´ string (v√≠ d·ª•: "14¬∞" -> 14.0)"""
    if not temp_str:
        return None
    try:
        # Lo·∫°i b·ªè k√Ω t·ª± ¬∞ v√† kho·∫£ng tr·∫Øng
        temp_str = temp_str.replace('¬∞', '').replace('¬∞C', '').strip()
        return float(temp_str)
    except:
        return None

def parse_pressure(pressure_str):
    """Parse √°p su·∫•t t·ª´ string (v√≠ d·ª•: "1028 hPa" -> 1028.0)"""
    if not pressure_str:
        return None
    try:
        # Lo·∫°i b·ªè "hPa" v√† kho·∫£ng tr·∫Øng
        pressure_str = pressure_str.replace('hPa', '').strip()
        return float(pressure_str)
    except:
        return None

def parse_wind(wind_str):
    """Parse gi√≥ t·ª´ string (v√≠ d·ª•: "6.92 km/h" -> 6.92)"""
    if not wind_str:
        return None
    try:
        # Lo·∫°i b·ªè "km/h" v√† kho·∫£ng tr·∫Øng
        wind_str = wind_str.replace('km/h', '').strip()
        return float(wind_str)
    except:
        return None

def parse_rain(rain_str):
    """Parse l∆∞·ª£ng m∆∞a t·ª´ string (v√≠ d·ª•: "0 mm" -> 0.0)"""
    if not rain_str:
        return None
    try:
        # Lo·∫°i b·ªè "mm" v√† kho·∫£ng tr·∫Øng
        rain_str = rain_str.replace('mm', '').strip()
        return float(rain_str)
    except:
        return None

def parse_cloud(cloud_str):
    """Parse m√¢y t·ª´ string (c√≥ th·ªÉ l√† text m√¥ t·∫£)"""
    # Thoitiet360 c√≥ th·ªÉ kh√¥ng c√≥ % m√¢y, ch·ªâ c√≥ m√¥ t·∫£
    # Tr·∫£ v·ªÅ None n·∫øu kh√¥ng parse ƒë∆∞·ª£c
    return None

def crawl_thoitiet360(city_key='ha-noi'):
    """
    Crawl d·ªØ li·ªáu d·ª± b√°o ng√†y h√¥m nay t·ª´ thoitiet360.edu.vn
    
    Args:
        city_key: 'ha-noi', 'vinh', ho·∫∑c 'ho-chi-minh'
    
    Returns:
        List of dicts v·ªõi d·ªØ li·ªáu d·ª± b√°o ng√†y h√¥m nay
    """
    url = CITY_URLS.get(city_key)
    if not url:
        print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y URL cho th√†nh ph·ªë: {city_key}")
        return []
    
    print(f"\nüîç ƒêang crawl d·ªØ li·ªáu t·ª´ thoitiet360.edu.vn cho {CITY_MAPPING.get(city_key, city_key)}...")
    print(f"   URL: {url}")
    
    # Retry logic: th·ª≠ l·∫°i t·ªëi ƒëa 3 l·∫ßn
    max_retries = 3
    retry_delay = 2  # Ngh·ªâ 2 gi√¢y gi·ªØa c√°c l·∫ßn th·ª≠
    
    for attempt in range(max_retries):
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7',
                'Connection': 'keep-alive'
            }
            
            # S·ª≠ d·ª•ng session ƒë·ªÉ gi·ªØ k·∫øt n·ªëi
            session = requests.Session()
            response = session.get(url, headers=headers, timeout=30)
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                if attempt < max_retries - 1:
                    print(f"   ‚ö†Ô∏è  HTTP {response.status_code}, th·ª≠ l·∫°i sau {retry_delay} gi√¢y...")
                    time.sleep(retry_delay)
                    continue
                else:
                    print(f"‚ùå L·ªói: HTTP {response.status_code} sau {max_retries} l·∫ßn th·ª≠")
                    return []
            
            # Th√†nh c√¥ng, tho√°t kh·ªèi v√≤ng l·∫∑p retry
            break
            
        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout, 
                requests.exceptions.RequestException) as e:
            if attempt < max_retries - 1:
                print(f"   ‚ö†Ô∏è  L·ªói k·∫øt n·ªëi: {str(e)[:50]}...")
                print(f"   ‚ö†Ô∏è  Th·ª≠ l·∫°i l·∫ßn {attempt + 2}/{max_retries} sau {retry_delay} gi√¢y...")
                time.sleep(retry_delay)
            else:
                print(f"‚ùå L·ªói k·∫øt n·ªëi sau {max_retries} l·∫ßn th·ª≠: {str(e)[:100]}")
                return []
        except Exception as e:
            print(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)[:100]}")
            return []
    
    try:
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        import re
        forecast_data = []
        today = datetime.now().date()
        
        # T√¨m t·∫•t c·∫£ c√°c heading c√≥ ch·ª©a pattern ng√†y (T2-T7, CN, ho·∫∑c s·ªë ng√†y/th√°ng)
        date_pattern = re.compile(r'(T[2-7]|CN|Ch·ªß nh·∫≠t|Th·ª© [2-7])\s*\d{1,2}/\d{1,2}', re.IGNORECASE)
        
        found_days = []
        
        # T√¨m t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ c√≥ ch·ª©a pattern ng√†y
        all_elements = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div', 'section', 'article'])
        
        for element in all_elements:
            text = element.get_text()
            
            # Ki·ªÉm tra xem c√≥ ch·ª©a pattern ng√†y kh√¥ng
            if date_pattern.search(text):
                # T√¨m nhi·ªát ƒë·ªô trong ph·∫ßn t·ª≠ n√†y (l·∫•y s·ªë ƒë·∫ßu ti√™n h·ª£p l√Ω)
                temp_matches = re.findall(r'(\d+)\s*¬∞', text)
                main_temp = None
                if temp_matches:
                    for temp in temp_matches:
                        temp_val = int(temp)
                        # Nhi·ªát ƒë·ªô h·ª£p l√Ω cho Vi·ªát Nam: 0-50¬∞C
                        if 0 <= temp_val <= 50:
                            main_temp = temp
                            break
                
                if main_temp:
                    # T√¨m c√°c th√¥ng s·ªë kh√°c
                    pressure_matches = re.findall(r'(\d{3,4})\s*hPa', text)
                    wind_matches = re.findall(r'(\d+\.?\d*)\s*km/h', text)
                    rain_matches = re.findall(r'(\d+\.?\d*)\s*mm', text)
                    
                    # Ki·ªÉm tra xem ƒë√£ c√≥ ng√†y n√†y ch∆∞a (tr√°nh tr√πng l·∫∑p)
                    day_key = f"{main_temp}_{pressure_matches[0] if pressure_matches else 'none'}"
                    if day_key not in [d.get('key', '') for d in found_days]:
                        found_days.append({
                            'key': day_key,
                            'temp': main_temp,
                            'pressure': pressure_matches[0] if pressure_matches else None,
                            'wind': wind_matches[0] if wind_matches else None,
                            'rain': rain_matches[0] if rain_matches else None,
                            'text': text[:200]
                        })
        
        # Ch·ªâ l·∫•y ng√†y h√¥m nay (ng√†y ƒë·∫ßu ti√™n)
        found_days = found_days[:1]
        
        print(f"   T√¨m th·∫•y {len(found_days)} ng√†y d·ª± b√°o (ch·ªâ l·∫•y h√¥m nay)")
        
        # T·∫°o record cho ng√†y h√¥m nay
        for idx, day_data in enumerate(found_days):
            forecast_date = today  # Ch·ªâ l·∫•y ng√†y h√¥m nay
            
            # L√†m s·∫°ch raw_text: thay th·∫ø k√Ω t·ª± xu·ªëng d√≤ng b·∫±ng kho·∫£ng tr·∫Øng
            raw_text = day_data.get('text', '')
            raw_text = raw_text.replace('\n', ' ').replace('\r', ' ').strip()
            raw_text = ' '.join(raw_text.split())  # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
            raw_text = raw_text[:100]  # Gi·ªõi h·∫°n 100 k√Ω t·ª±
            
            record = {
                'city': CITY_MAPPING.get(city_key, city_key),
                'city_key': city_key,
                'date': forecast_date.strftime('%Y-%m-%d'),
                'source': 'thoitiet360',
                'crawled_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'Temp': parse_temperature(day_data['temp']) if day_data['temp'] else None,
                'Pressure': parse_pressure(day_data['pressure']) if day_data['pressure'] else None,
                'Wind': parse_wind(day_data['wind']) if day_data['wind'] else None,
                'Rain': parse_rain(day_data['rain']) if day_data['rain'] else None,
                'Cloud': None,
                'raw_text': raw_text
            }
            
            forecast_data.append(record)
            print(f"   ‚úì Ng√†y {forecast_date.strftime('%Y-%m-%d')}: Temp={record['Temp']}¬∞C, Pressure={record['Pressure']}hPa, Wind={record['Wind']}km/h, Rain={record['Rain']}mm")
        
        # N·∫øu kh√¥ng parse ƒë∆∞·ª£c b·∫±ng c√°ch tr√™n, th·ª≠ c√°ch kh√°c
        if not forecast_data:
            print("   ‚ö†Ô∏è  Kh√¥ng parse ƒë∆∞·ª£c d·ªØ li·ªáu b·∫±ng c√°ch th√¥ng th∆∞·ªùng, th·ª≠ c√°ch kh√°c...")
            
            # In ra m·ªôt ph·∫ßn HTML ƒë·ªÉ debug
            print(f"   HTML sample (first 1000 chars): {response.text[:1000]}")
        
        return forecast_data
        
    except Exception as e:
        print(f"‚ùå L·ªói khi parse d·ªØ li·ªáu: {str(e)[:100]}")
        return []

def preprocess_thoitiet360_data(df):
    """
    Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ thoitiet360 ƒë·ªÉ so s√°nh (kh√¥ng c·∫ßn c√°c c·ªôt cho training)
    
    Args:
        df: DataFrame t·ª´ crawl_thoitiet360
    
    Returns:
        DataFrame ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω, ch·ªâ gi·ªØ c√°c c·ªôt c·∫ßn thi·∫øt ƒë·ªÉ so s√°nh
    """
    df = df.copy()
    
    # 1. Mapping t√™n th√†nh ph·ªë sang format database
    city_mapping = {
        'H√† N·ªôi': 'ha-noi',
        'Vinh': 'vinh',
        'H·ªì Ch√≠ Minh': 'ho-chi-minh-city'
    }
    
    if 'city' in df.columns:
        df['city'] = df['city'].map(city_mapping).fillna(df['city'])
    
    # 2. T·∫°o datetime t·ª´ date (m·∫∑c ƒë·ªãnh 00:00:00)
    if 'date' in df.columns:
        df['datetime'] = pd.to_datetime(df['date'] + ' 00:00:00')
        df['datetime'] = df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')
    
    # 3. ƒê·∫£m b·∫£o c√°c c·ªôt s·ªë l√† numeric
    numeric_cols = ['Temp', 'Pressure', 'Wind', 'Rain', 'Cloud', 'Gust']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        else:
            df[col] = None
    
    # 4. Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt c·∫ßn thi·∫øt ƒë·ªÉ so s√°nh
    columns_to_keep = ['city', 'date', 'datetime', 'Temp', 'Pressure', 'Wind', 'Rain', 'Cloud', 'Gust']
    columns_to_keep = [col for col in columns_to_keep if col in df.columns]
    df = df[columns_to_keep]
    
    # 5. Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt
    columns_to_drop = ['raw_text', 'city_key', 'source', 'crawled_at', 'Time']
    for col in columns_to_drop:
        if col in df.columns:
            df = df.drop(columns=[col])
    
    # 6. S·∫Øp x·∫øp theo city v√† date
    if 'city' in df.columns and 'date' in df.columns:
        df = df.sort_values(['city', 'date']).reset_index(drop=True)
    
    return df

def save_to_csv(data, filename='thoitiet360_data.csv'):
    """L∆∞u d·ªØ li·ªáu g·ªëc v√†o file CSV"""
    try:
        if not data:
            print("‚ö†Ô∏è  Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l∆∞u")
            return
        
        # L∆∞u file g·ªëc (ch∆∞a ti·ªÅn x·ª≠ l√Ω)
        df_raw = pd.DataFrame(data)
        if 'raw_text' in df_raw.columns:
            df_raw['raw_text'] = df_raw['raw_text'].astype(str).str.replace('\n', ' ').str.replace('\r', ' ').str.strip()
            df_raw['raw_text'] = df_raw['raw_text'].str[:100]
        
        df_raw.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"‚úÖ ƒê√£ l∆∞u {len(df_raw)} records v√†o {filename}")
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u CSV: {str(e)}")

def save_to_database(df):
    """L∆∞u d·ªØ li·ªáu v√†o database"""
    try:
        from database import init_database, get_db_connection
        import os
        
        # Kh·ªüi t·∫°o database
        init_database()
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        inserted = 0
        updated = 0
        
        for _, row in df.iterrows():
            # Ki·ªÉm tra xem ƒë√£ c√≥ record ch∆∞a (d·ª±a tr√™n city v√† date)
            cursor.execute('''
                SELECT id FROM thoitiet360_data 
                WHERE city = ? AND date = ?
            ''', (row['city'], row['date']))
            
            existing = cursor.fetchone()
            
            if existing:
                # Update record ƒë√£ t·ªìn t·∫°i
                cursor.execute('''
                    UPDATE thoitiet360_data 
                    SET datetime = ?, Temp = ?, Pressure = ?, Wind = ?, Rain = ?, Cloud = ?, Gust = ?
                    WHERE city = ? AND date = ?
                ''', (
                    row.get('datetime'),
                    row.get('Temp'),
                    row.get('Pressure'),
                    row.get('Wind'),
                    row.get('Rain'),
                    row.get('Cloud'),
                    row.get('Gust'),
                    row['city'],
                    row['date']
                ))
                updated += 1
            else:
                # Insert record m·ªõi
                cursor.execute('''
                    INSERT INTO thoitiet360_data 
                    (city, date, datetime, Temp, Pressure, Wind, Rain, Cloud, Gust)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    row['city'],
                    row['date'],
                    row.get('datetime'),
                    row.get('Temp'),
                    row.get('Pressure'),
                    row.get('Wind'),
                    row.get('Rain'),
                    row.get('Cloud'),
                    row.get('Gust')
                ))
                inserted += 1
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ ƒê√£ l∆∞u v√†o database: {inserted} records m·ªõi, {updated} records c·∫≠p nh·∫≠t")
        return inserted + updated
        
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u v√†o database: {str(e)}")
        import traceback
        traceback.print_exc()
        return 0

def main():
    """Crawl d·ªØ li·ªáu cho t·∫•t c·∫£ c√°c th√†nh ph·ªë"""
    # Ki·ªÉm tra v√† pull c·∫≠p nh·∫≠t t·ª´ GitHub tr∆∞·ªõc
    check_and_pull_from_github()
    
    print("\n" + "="*70)
    print("CRAWL D·ªÆ LI·ªÜU NG√ÄY H√îM NAY T·ª™ THOITIET360.EDU.VN")
    print("="*70)
    
    all_data = []
    
    cities = ['ha-noi', 'vinh', 'ho-chi-minh']
    
    for idx, city_key in enumerate(cities, 1):
        print(f"\n[{idx}/{len(cities)}] ƒêang crawl {CITY_MAPPING.get(city_key, city_key)}...")
        data = crawl_thoitiet360(city_key)
        all_data.extend(data)
        
        # Ngh·ªâ gi·ªØa c√°c request ƒë·ªÉ tr√°nh b·ªã ch·∫∑n
        if idx < len(cities):
            time.sleep(3)  # Ngh·ªâ 3 gi√¢y gi·ªØa c√°c th√†nh ph·ªë
    
    print(f"\n{'='*70}")
    print(f"T·ªîNG K·∫æT: Crawl ƒë∆∞·ª£c {len(all_data)} records")
    print(f"{'='*70}")
    
    if all_data:
        # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
        df = pd.DataFrame(all_data)
        df_processed = preprocess_thoitiet360_data(df)
        
        # L∆∞u v√†o CSV (file g·ªëc)
        save_to_csv(all_data, 'thoitiet360_data.csv')
        
        # L∆∞u v√†o database
        print("\nüíæ ƒêang l∆∞u v√†o database...")
        save_to_database(df_processed)
        
        # Hi·ªÉn th·ªã summary
        print("\nüìä T√≥m t·∫Øt d·ªØ li·ªáu:")
        if not df.empty:
            print(df.groupby('city').size())
            print("\nM·∫´u d·ªØ li·ªáu ƒë√£ l∆∞u:")
            print(df_processed[['city', 'date', 'Temp', 'Pressure', 'Wind', 'Rain']].head(10).to_string())
    else:
        print("‚ö†Ô∏è  Kh√¥ng crawl ƒë∆∞·ª£c d·ªØ li·ªáu n√†o!")

if __name__ == '__main__':
    main()

